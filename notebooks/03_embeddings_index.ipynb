{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "DYZdVdLoRiyI"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1484cf9a32a6489b8789cef10e0fa098": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_203d942066144a18b0e364329167f1a2",
              "IPY_MODEL_61416a01f39a4896b226765a93ca4834",
              "IPY_MODEL_2f757706f59f4f738c0eec778031544b"
            ],
            "layout": "IPY_MODEL_9ca455779fb34f3682c7251619ea26e1"
          }
        },
        "203d942066144a18b0e364329167f1a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_478e3e3499614407bc52d60df888dd49",
            "placeholder": "​",
            "style": "IPY_MODEL_fb178d1d39a746e79b1ed587e8da788b",
            "value": "Map (num_proc=2):  85%"
          }
        },
        "61416a01f39a4896b226765a93ca4834": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_63576c9406194b1a93acc58f01488080",
            "max": 1000000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0a275e728ccb41018aab605b322e0d6d",
            "value": 850000
          }
        },
        "2f757706f59f4f738c0eec778031544b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ad9242c1aaee4284a15275df03f40ec5",
            "placeholder": "​",
            "style": "IPY_MODEL_34603f7aef7f4ea5ae509250a562da50",
            "value": " 850000/1000000 [25:14&lt;04:52, 512.42 examples/s]"
          }
        },
        "9ca455779fb34f3682c7251619ea26e1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "478e3e3499614407bc52d60df888dd49": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb178d1d39a746e79b1ed587e8da788b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "63576c9406194b1a93acc58f01488080": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a275e728ccb41018aab605b322e0d6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ad9242c1aaee4284a15275df03f40ec5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "34603f7aef7f4ea5ae509250a562da50": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Data preparation: Embeddings and Indexing\n",
        "Este notebook refere-se à etapa de preparação dos dados, contemplando o pipeline de vetorização dos dados textuais e armazenamento dos vetores semânticos para consulta. Os passos aqui apresentados são:\n",
        "- Chunking dos documentos\n",
        "- Vetorização (embeddings)\n",
        "- Teste e indexação com FAISS\n",
        "- Indexação e persistência em banco Qdrant\n",
        "- Consulta de checagem da indexação\n",
        "\n",
        "Para esta etapa, **será utilizado apenas o dataset Quati, com a tabela de `passages`**, tendo em vista que é esse conjunto de dados que contém os documentos necessários para recuperação da informação e é conjunto que define o problema de negócio proposto.\n",
        "\n",
        "Como a coleta dos dados foi feito diretamente do Hugging Face, **o pré-processamento textual (limpeza e normalização) foi replicado do notebook `02_preprocessing.ipynb`** para padronização e consistência nas transformações aplicadas no projeto."
      ],
      "metadata": {
        "id": "hixY49SBOj6A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Instalações e importações"
      ],
      "metadata": {
        "id": "DYZdVdLoRiyI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check CUDA version\n",
        "!nvcc --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g-KRs-lyVjDe",
        "outputId": "2c5f459f-421d-46e7-b816-7e6268ae55be"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: nvcc: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "17cVm1hIOTnn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c717e6d7-d1e3-4218-fc20-b6fc24e09e34"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets<4.0.0 in /usr/local/lib/python3.12/dist-packages (3.6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets<4.0.0) (3.20.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from datasets<4.0.0) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets<4.0.0) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets<4.0.0) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets<4.0.0) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets<4.0.0) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.12/dist-packages (from datasets<4.0.0) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets<4.0.0) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets<4.0.0) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0) (2025.3.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.12/dist-packages (from datasets<4.0.0) (0.36.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from datasets<4.0.0) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets<4.0.0) (6.0.3)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0) (3.13.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets<4.0.0) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets<4.0.0) (1.2.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets<4.0.0) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets<4.0.0) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets<4.0.0) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets<4.0.0) (2025.11.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets<4.0.0) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets<4.0.0) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets<4.0.0) (2025.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0) (1.22.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets<4.0.0) (1.17.0)\n",
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.12/dist-packages (1.13.2)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (25.0)\n",
            "Requirement already satisfied: qdrant-client in /usr/local/lib/python3.12/dist-packages (1.16.2)\n",
            "Requirement already satisfied: grpcio>=1.41.0 in /usr/local/lib/python3.12/dist-packages (from qdrant-client) (1.76.0)\n",
            "Requirement already satisfied: httpx>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from httpx[http2]>=0.20.0->qdrant-client) (0.28.1)\n",
            "Requirement already satisfied: numpy>=1.26 in /usr/local/lib/python3.12/dist-packages (from qdrant-client) (2.0.2)\n",
            "Requirement already satisfied: portalocker<4.0,>=2.7.0 in /usr/local/lib/python3.12/dist-packages (from qdrant-client) (3.2.0)\n",
            "Requirement already satisfied: protobuf>=3.20.0 in /usr/local/lib/python3.12/dist-packages (from qdrant-client) (5.29.5)\n",
            "Requirement already satisfied: pydantic!=2.0.*,!=2.1.*,!=2.2.0,>=1.10.8 in /usr/local/lib/python3.12/dist-packages (from qdrant-client) (2.12.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.26.14 in /usr/local/lib/python3.12/dist-packages (from qdrant-client) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions~=4.12 in /usr/local/lib/python3.12/dist-packages (from grpcio>=1.41.0->qdrant-client) (4.15.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (4.12.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (0.16.0)\n",
            "Requirement already satisfied: h2<5,>=3 in /usr/local/lib/python3.12/dist-packages (from httpx[http2]>=0.20.0->qdrant-client) (4.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=2.0.*,!=2.1.*,!=2.2.0,>=1.10.8->qdrant-client) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic!=2.0.*,!=2.1.*,!=2.2.0,>=1.10.8->qdrant-client) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic!=2.0.*,!=2.1.*,!=2.2.0,>=1.10.8->qdrant-client) (0.4.2)\n",
            "Requirement already satisfied: hyperframe<7,>=6.1 in /usr/local/lib/python3.12/dist-packages (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client) (6.1.0)\n",
            "Requirement already satisfied: hpack<5,>=4.1 in /usr/local/lib/python3.12/dist-packages (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client) (4.1.0)\n"
          ]
        }
      ],
      "source": [
        "# Instalações\n",
        "!pip install \"datasets<4.0.0\"\n",
        "!pip install faiss-cpu #faiss-gpu-cu12\n",
        "!pip install qdrant-client"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Imports\n",
        "# Utils\n",
        "import warnings\n",
        "from typing import List\n",
        "from multiprocessing import cpu_count\n",
        "cpu_c = cpu_count()\n",
        "print(f\"CPU count: {cpu_c}\")\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# NLP\n",
        "import re\n",
        "import unicodedata\n",
        "\n",
        "# Manipulação dos dados\n",
        "import numpy as np\n",
        "from datasets import load_dataset\n",
        "\n",
        "# Embeddings\n",
        "from transformers import AutoTokenizer\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# Indexação e persistência vetorial\n",
        "import faiss\n",
        "from qdrant_client import QdrantClient\n",
        "from qdrant_client.models import VectorParams, Distance, PointStruct"
      ],
      "metadata": {
        "id": "O7rQZPv4SM0y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6782229d-352d-42dd-f9f3-308f710731cc"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU count: 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:torchao.kernel.intmm:Warning: Detected no triton, on systems without Triton certain kernels will not work\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Carregamento dos dados e limpeza textual"
      ],
      "metadata": {
        "id": "UzD8VT_gRlaM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Quati dataset\n",
        "quati_ds = load_dataset(\"unicamp-dl/quati\", \"quati_1M_passages\", trust_remote_code=True)[\"quati_1M_passages\"]\n",
        "\n",
        "print(quati_ds)\n",
        "print(\"-\" * 100)\n",
        "quati_ds[:3]"
      ],
      "metadata": {
        "id": "RixBJDjtRnWi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "807ad06f-bdb1-4cf1-dba7-46d00741f521"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset({\n",
            "    features: ['passage_id', 'passage'],\n",
            "    num_rows: 1000000\n",
            "})\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'passage_id': ['clueweb22-pt0000-00-00003_1',\n",
              "  'clueweb22-pt0000-00-00003_2',\n",
              "  'clueweb22-pt0000-00-00003_3'],\n",
              " 'passage': ['Se você precisar de ajuda, visite o website nacional sobre a COVID-19 ou ligue para a linha de apoio à COVID-19 808 24 24 24 Perguntas mais frequentes Posso viajar entre Sintra e Cascais? Quais são as restrições de viagem em Cascais? Qual o número de telefone de apoio para a COVID 19 em Cascais? Preciso utilizar máscara facial no transporte público em Cascais? A prática do distanciamento social é compulsória em Cascais? O que eu devo fazer caso apresente sintomas da COVID-19 quando chegar em Cascais? Última atualização: 25 Abr 2022 Aplicam-se exceções, para detalhes completos: European Union. Estamos trabalhando ininterruptamente para lhe trazer as últimas informações de viagem relacionadas à COVID-19. Esta informação é compilada a partir de fontes oficiais. Ao melhor de nosso conhecimento, está correta de acordo com a última atualização. Visite Avisos de Viagem Rome2rio para ajuda geral. Perguntas & Respostas Qual a maneira mais econômica de ir de Sintra para Cascais? Qual a maneira mais rápida de ir de Sintra para Cascais? Existe um ônibus direto entre Sintra e Cascais? Qual a distância entre Sintra e Cascais? Como viajar de Sintra para Cascais sem carro? Qual a distância entre Sintra e Cascais? Aonde pegar ônibus de Sintra para Cascais?',\n",
              "  'Qual a parada final de Sintra para Cascais ônibus? Posso dirigir de Sintra para Cascais? Quais são as opções de acomodação perto de Cascais? Abrir visualização de mapa Distância: 12.2 km Duração 33 min Quais empresas operam serviços entre Sintra, Portugal e Cascais, Portugal? Operadores de ônibus Scott URB FlixBus Outros Operadoras BlaBlaCar Táxi de Sintra para Cascais Mais Perguntas e Respostas Existe opções de transporte compartilhado entre Sintra e Cascais? Cascais, Portugal Cascais MHC é uma vila portuguesa, sede do município (concelho) homónimo, o qual é parte do distrito e da área metropolitana de Lisboa. Em 2016, totalizava habitantes distribuídos por uma área de. O município subdivide-se em quatro freguesias (Alcabideche, Carcavelos e Parede, Cascais e Estoril e São Domingos de Rana). Apesar do seu estatuto de vil ... Coisas para fazer em Cascais Quinta da Regaleira O Palácio da Regaleira é o edifício principal e o nome mais comum do palácio da Quinta da Regaleira. Também é designado Palácio do Monteiro dos Milhões, denominação esta associada à alcunha do seu primeiro proprietário foi António Augusto que foi distinguido pelo rei Dom Carlos I em 16 de agosto de 1904 como barão de Almeida. Casino Estoril',\n",
              "  '\"O Casino Estoril fica localizado no Estoril, a 18 km de Lisboa e a 20 km do Aeroporto de Lisboa. É hoje o maior casino da Europa e é gerido pela empresa Estoril-Sol SGPS S.A.. Cabo da Roca O Cabo da Roca é o ponto mais ocidental de Portugal continental, assim como da Europa continental. Situa-se na freguesia de Colares, concelho de Sintra e distrito de Lisboa. O local é visitável, não até ao extremo mas até uma zona à altitude de 140 m. O cabo forma o extremo ocidental da Serra de Sintra, precipitando-se sobre o Oceano Atlântico. As suas coordenadas geográficas são N 38º46\\'51\\\\\"\", W 9º30\\'2\\\\\"\". Lugares para ficar em Cascais €226 InterContinental Cascais-Estoril, an IHG Hotel 4.8 Exceptional €180 Hotel Cascais Miragem 4.8 Exceptional €133 Grande Real Villa Italia 4.8 Exceptional Rome2rio facilita as viagens de Sintra a Cascais.\"']}"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function definition to clean text\n",
        "HTML_TAG = re.compile(r\"<[^>]+>\")\n",
        "URL = re.compile(r\"https?://\\S+|www\\.\\S+\")\n",
        "EMAIL = re.compile(r\"\\S+@\\S+\")\n",
        "MULTISPACE = re.compile(r\"\\s+\")\n",
        "\n",
        "def clean_text(text: str) -> str:\n",
        "    \"\"\"\n",
        "    Realiza limpeza textual baseada em expressões regulares.\n",
        "    As transformações aplicadas são:\n",
        "    - Normalização Unicode\n",
        "    - Remoção de ruídos (como sequência de \"===\" ou \" ---\")\n",
        "    - Remoção de HTML, URLs e E-mails\n",
        "    - Remoção de caracteres não-principais e de controle\n",
        "    - Normalização de espaços\n",
        "\n",
        "    Params:\n",
        "        text (str): Texto a ser limpo.\n",
        "\n",
        "    Returns:\n",
        "        str: Texto limpo.\n",
        "    \"\"\"\n",
        "    if not text: return \"\"\n",
        "\n",
        "    # Unicode normalization (NFKC)\n",
        "    text = unicodedata.normalize('NFKC', text)\n",
        "\n",
        "    # Remove noise (repeated sequences such as \"=====\" or \"----\")\n",
        "    text = re.sub(r'([^a-zA-Z0-9\\s])\\1{3,}', ' ', text)\n",
        "\n",
        "    # Remove HTML, URLs, E-mails\n",
        "    text = HTML_TAG.sub('', text)\n",
        "    text = URL.sub('', text)\n",
        "    text = EMAIL.sub('', text)\n",
        "\n",
        "    # Clean non-printable characters and control\n",
        "    text = \"\".join(ch for ch in text if unicodedata.category(ch)[0] != \"C\")\n",
        "\n",
        "    # Spaces normalization (useful for keeping cleaned chunks in RAG)\n",
        "    text = MULTISPACE.sub(' ', text).strip()\n",
        "\n",
        "    return text.lower()"
      ],
      "metadata": {
        "id": "6wz9EGzwqONR"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Clean Quati passages\n",
        "def clean_quati_passages(batch):\n",
        "    batch[\"passage\"] = [clean_text(p) for p in batch[\"passage\"]]\n",
        "    return batch\n",
        "\n",
        "quati_ds = quati_ds.map(\n",
        "    clean_quati_passages,\n",
        "    batched=True,\n",
        "    batch_size=10_000,\n",
        "    num_proc=cpu_c\n",
        ")\n",
        "\n",
        "quati_ds[\"passage\"][:2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jr6cnx55qvXI",
        "outputId": "59f05170-39ca-4720-b335-1a114671f8ae"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['se você precisar de ajuda, visite o website nacional sobre a covid-19 ou ligue para a linha de apoio à covid-19 808 24 24 24 perguntas mais frequentes posso viajar entre sintra e cascais? quais são as restrições de viagem em cascais? qual o número de telefone de apoio para a covid 19 em cascais? preciso utilizar máscara facial no transporte público em cascais? a prática do distanciamento social é compulsória em cascais? o que eu devo fazer caso apresente sintomas da covid-19 quando chegar em cascais? última atualização: 25 abr 2022 aplicam-se exceções, para detalhes completos: european union. estamos trabalhando ininterruptamente para lhe trazer as últimas informações de viagem relacionadas à covid-19. esta informação é compilada a partir de fontes oficiais. ao melhor de nosso conhecimento, está correta de acordo com a última atualização. visite avisos de viagem rome2rio para ajuda geral. perguntas & respostas qual a maneira mais econômica de ir de sintra para cascais? qual a maneira mais rápida de ir de sintra para cascais? existe um ônibus direto entre sintra e cascais? qual a distância entre sintra e cascais? como viajar de sintra para cascais sem carro? qual a distância entre sintra e cascais? aonde pegar ônibus de sintra para cascais?',\n",
              " 'qual a parada final de sintra para cascais ônibus? posso dirigir de sintra para cascais? quais são as opções de acomodação perto de cascais? abrir visualização de mapa distância: 12.2 km duração 33 min quais empresas operam serviços entre sintra, portugal e cascais, portugal? operadores de ônibus scott urb flixbus outros operadoras blablacar táxi de sintra para cascais mais perguntas e respostas existe opções de transporte compartilhado entre sintra e cascais? cascais, portugal cascais mhc é uma vila portuguesa, sede do município (concelho) homónimo, o qual é parte do distrito e da área metropolitana de lisboa. em 2016, totalizava habitantes distribuídos por uma área de. o município subdivide-se em quatro freguesias (alcabideche, carcavelos e parede, cascais e estoril e são domingos de rana). apesar do seu estatuto de vil ... coisas para fazer em cascais quinta da regaleira o palácio da regaleira é o edifício principal e o nome mais comum do palácio da quinta da regaleira. também é designado palácio do monteiro dos milhões, denominação esta associada à alcunha do seu primeiro proprietário foi antónio augusto que foi distinguido pelo rei dom carlos i em 16 de agosto de 1904 como barão de almeida. casino estoril']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chunking\n",
        "Para realização do chunking dos documentos, é obrigatoriamente necessário **utilizar o mesmo modelo de vetorização dos textos na tokenização** (útil para o chunking de dados por tokens, que mantém a semântica no trecho). No tópico de vetorização, tem o detalhamento do modelo selecionado.\n",
        "\n",
        "Os chunks foram delimitados com até **256 tokens** com **overlap de 64 tokens** entre os chunks.\n",
        "\n",
        "Esse modelo é relativamente leve e pouco custoso, além de possuir semântica multilinguística e ser focado para busca semântica.\n"
      ],
      "metadata": {
        "id": "hTCkgwZsRoV2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\n",
        "    \"intfloat/multilingual-e5-small\",\n",
        "    # device=\"cuda\"\n",
        ")\n",
        "\n",
        "print(f\"Model selected: {tokenizer.name_or_path}\")\n",
        "print(f\"Tokenizer max length: {tokenizer.model_max_length}\")\n",
        "print(f\"Tokenizer vocab size: {tokenizer.vocab_size}\")"
      ],
      "metadata": {
        "id": "B9fUqQ0sRpYq"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to chunk text\n",
        "def chunk_text(text: str, max_tokens: int = 256, overlap: int = 64) -> List[str]:\n",
        "    \"\"\"\n",
        "    Divide um texto em trechos (chunks) a partir de tokens, mantendo um overlap entre os trechos.\n",
        "    Cada trecho é representado por uma lista de tokens contendo até max_tokens palavras.\n",
        "    O overlap entre os trechos é definido por overlap tokens.\n",
        "\n",
        "    Params:\n",
        "        text (str): Texto a ser dividido em trechos.\n",
        "        max_tokens (int): Número máximo de tokens por trecho.\n",
        "        overlap (int): Número de tokens de overlap entre os trechos.\n",
        "\n",
        "    Returns:\n",
        "        List[str]: Lista de trechos do texto.\n",
        "    \"\"\"\n",
        "    # Create tokens\n",
        "    tokens = tokenizer(\n",
        "        text,\n",
        "        truncation=False,\n",
        "        return_offsets_mapping=False,\n",
        "        add_special_tokens=False,\n",
        "    )[\"input_ids\"]\n",
        "\n",
        "    # Set chunks\n",
        "    chunks = []\n",
        "    for i in range(0, len(tokens), max_tokens - overlap):\n",
        "        # Set chunk ids\n",
        "        chunk_ids = tokens[i:i + max_tokens]\n",
        "        if not chunk_ids:\n",
        "            continue\n",
        "\n",
        "        # Get chunks\n",
        "        chunk = tokenizer.decode(chunk_ids, skip_special_tokens=True)\n",
        "        chunks.append(chunk)\n",
        "    return chunks\n",
        "\n",
        "\n",
        "# Function alternative: uses offsets mapping to split the chunks by tokens\n",
        "def chunk_by_tokens(text, chunk_size=384, overlap=64):\n",
        "    tokens = tokenizer(\n",
        "        text,\n",
        "        return_offsets_mapping=True,\n",
        "        add_special_tokens=False,\n",
        "    )\n",
        "    input_ids = tokens[\"input_ids\"]\n",
        "    offsets = tokens[\"offset_mapping\"]\n",
        "\n",
        "    chunks = []\n",
        "    start = 0\n",
        "\n",
        "    while start < len(input_ids):\n",
        "        end = start + chunk_size\n",
        "        chunk_offsets = offsets[start:end]\n",
        "        char_start = chunk_offsets[0][0]\n",
        "        char_end = chunk_offsets[-1][1]\n",
        "        chunks.append(text[char_start:char_end])\n",
        "        start += chunk_size - overlap\n",
        "\n",
        "    return chunks"
      ],
      "metadata": {
        "id": "SE26n5-hWkpT"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Applying chunks into documents\n",
        "def apply_chunks(batch):\n",
        "    batch[\"chunks\"] = [chunk_text(doc) for doc in batch[\"passage\"]]\n",
        "    return batch\n",
        "\n",
        "quati_ds = quati_ds.map(\n",
        "    apply_chunks,\n",
        "    batched=True,\n",
        "    batch_size=10_000,\n",
        "    num_proc=cpu_c\n",
        ")\n",
        "\n",
        "quati_ds.select_columns([\"chunks\", \"passage\"])[:2]"
      ],
      "metadata": {
        "id": "z1zLldXZXGOn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105,
          "referenced_widgets": [
            "1484cf9a32a6489b8789cef10e0fa098",
            "203d942066144a18b0e364329167f1a2",
            "61416a01f39a4896b226765a93ca4834",
            "2f757706f59f4f738c0eec778031544b",
            "9ca455779fb34f3682c7251619ea26e1",
            "478e3e3499614407bc52d60df888dd49",
            "fb178d1d39a746e79b1ed587e8da788b",
            "63576c9406194b1a93acc58f01488080",
            "0a275e728ccb41018aab605b322e0d6d",
            "ad9242c1aaee4284a15275df03f40ec5",
            "34603f7aef7f4ea5ae509250a562da50"
          ]
        },
        "outputId": "d9c0e770-cc2e-4ee8-e583-27daf1694d0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map (num_proc=2):   0%|          | 0/1000000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1484cf9a32a6489b8789cef10e0fa098"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (724 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (519 > 512). Running this sequence through the model will result in indexing errors\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Flatten the chunks for indexing\n",
        "texts = []\n",
        "metadatas = []\n",
        "\n",
        "for row in quati_ds:\n",
        "    for idx, chunk in enumerate(row[\"chunks\"]):\n",
        "        texts.append(chunk)\n",
        "        metadatas.append({\n",
        "            \"passage_id\": row[\"passage_id\"],\n",
        "            \"chunk_id\": idx\n",
        "        })\n",
        "\n",
        "print(f\"Total of chunks: {len(texts)}\")"
      ],
      "metadata": {
        "id": "BHykf9paE0O-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Vetorização dos dados (embeddings)\n",
        "Na seleção do modelo para vetorização dos textos, foram buscado modelos recentes no Hugging Face que apresentem boas perfomances e precisão, com semântica multilinguística e, principalmente, com baixa latência e alta velocidade em inferência e no uso.\n",
        "\n",
        "A partir de uma breve pesquisa de modelos para embedding, o modelo que melhor atende as especificações necessárias foi o modelo `Multilingual-E5-Small`."
      ],
      "metadata": {
        "id": "nrfyrSbKRrOL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dentre os modelos considerados, mantendo o foco em velocidade e baixo custo, abaixo segue a descrição das possibilidades avaliadas:\n",
        "\n",
        "| **Modelo**                     | **Descrição**                                                                                                      | **Latência/Velocidade**                                        | **Memória**                              | **Recursos/Observações**                                                                 |\n",
        "|---------------------------------|---------------------------------------------------------------------------------------------------------------------|---------------------------------------------------------------|------------------------------------------|-------------------------------------------------------------------------------------------|\n",
        "| **Multilingual-E5-Small**       | Modelo \"all-rounder\" otimizado para buscas semânticas em mais de 100 idiomas.                                       | \"Campeão de velocidade\", latência de 16ms, até 7x mais rápido que modelos baseados em LLMs. | Menos de 200MB de RAM                   | Ideal para RAGs em produção que exigem alta taxa de transferência (QPS).                 |\n",
        "| **EmbeddingGemma-300M**        | Lançado em setembro de 2025 pelo Google, baseado na arquitetura Gemma 3.                                             | Sub-segundo, projetado para execução local e on-device.         | Requer apenas 300MB de RAM (cai para 100-200MB com quantização). | Suporta Matryoshka (MRL), permitindo reduzir vetores de 768 para 128 dimensões sem grande perda de precisão. |\n",
        "| **BGE-Small-v1.5**             | Versão compacta da família BAAI, focada em tarefas de recuperação técnica e RAG.                                     | Latência competitiva abaixo de 30ms.                           | Semelhante ao E5-Small, utiliza dimensões reduzidas (384). | Melhor para quem precisa de estabilidade na distribuição de similaridade (evita scores inflados). |\n",
        "| **MPNet-Base-v2 (Multilingual)** | Modelo clássico para detecção de paráfrases e similaridade curta.                                                   | Rápido (~25ms), mas superado pelos modelos acima em precisão de busca. | ~420MB                                  | Limitado a contextos curtos (128 tokens), dificultando uso em RAGs com parágrafos longos. |\n"
      ],
      "metadata": {
        "id": "zZkhA8LZ2vC3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize model\n",
        "model = SentenceTransformer(\n",
        "    \"intfloat/multilingual-e5-small\",\n",
        "    # device=\"cuda\"\n",
        ")"
      ],
      "metadata": {
        "id": "RhqVIpZdR1EF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create embeddings\n",
        "embeddings = model.encode(\n",
        "    texts,\n",
        "    show_progress_bar=True,\n",
        "    batch_size=1024,\n",
        "    normalize_embeddings=True   # For equalizing search methods\n",
        ")\n",
        "\n",
        "print(f\"Shape of embeddings: {embeddings.shape}\")\n",
        "print(f\"Quantidade de vetores: {embeddings.shape[0]}\")\n",
        "print(f\"Quantidade de dimensões: {embeddings.shape[1]}\")"
      ],
      "metadata": {
        "id": "ckyM3YYSIayH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Indexação e validação local\n",
        "A critério de aprendizado, a indexação feita nesse momento utilizará a biblioteca `FAISS` que permite buscas de similaridades rápidas através da crição de estruturas de dados (índices) que organizam os vetores de dados.\n",
        "\n",
        "Importante destacar que o FAISS é nativamente compatível com bibliotecas como Langchain e LlamaIndex para utilização em pipelines RAG.\n",
        "\n",
        "O método de indexação utilizado foi o `IndexFlat` que permite armazenamento dos vetores sem compressão e busca 100% exata comparando a consulta com cada vetor.\n",
        "\n",
        "Além desse método, é importante considerar o método `Inverted File Index` (IVF) que separa o espaço vetorial em clusters com k-means, e método HNSW baseado em grafo multicamadas."
      ],
      "metadata": {
        "id": "a_Nxv5w4R15B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create index\n",
        "dim = embeddings.shape[1]   # Vector dimension for embeddings\n",
        "index = faiss.IndexFlatIP(dim)  # Index Flat method uses Brute force search"
      ],
      "metadata": {
        "id": "lAbdc3ImOxPc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transfer index to GPU (index 0 for GPU)\n",
        "# gpu_res = faiss.StandardGpuResources()  # Create GPU resource\n",
        "\n",
        "# index = faiss.index_cpu_to_gpu(gpu_res, 0, index)"
      ],
      "metadata": {
        "id": "uDjn5G4ER4wC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add vectors (embeddings) into index\n",
        "index.add(embeddings)\n",
        "\n",
        "print(f\"Total of indexed vectors: {index.ntotal}\")"
      ],
      "metadata": {
        "id": "a-FIKOHHPykw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Quick search (top 5 chunks)\n",
        "k = 5\n",
        "distances, indices = index.search(np.array([embeddings[0]]), k)\n",
        "\n",
        "print(f\"Distances: {distances}\")\n",
        "print(f\"Indices: {indices}\")"
      ],
      "metadata": {
        "id": "6JGqfirWTnSS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Persist index and embeddings\n",
        "faiss.write_index(index, \"faiss_index.faiss\")   # Index\n",
        "np.save(\"embeddings.npy\", embeddings)   # Embeddings"
      ],
      "metadata": {
        "id": "v-LEz7aAUF4Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Persistência dos dados\n",
        "Para persistência real dos embeddings e utilização de um Vector DB dentro da aplicabilidade do projeto, optamos por utilizar o Qdrant."
      ],
      "metadata": {
        "id": "tDd_p3U9R5Op"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize DB\n",
        "client = QdrantClient(\":memory:\")"
      ],
      "metadata": {
        "id": "Fq8RZDr5R8Ni"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create colletion for chunks\n",
        "client.recreate_collection(\n",
        "    collection_name=\"quati_chunks\",\n",
        "    vectors_config=VectorParams(\n",
        "        size=dim,   # Size = Embeddings dimension\n",
        "        distance=Distance.COSINE    # Method to calculate distance\n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "id": "3okwG5NSVr8s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Upsert data\n",
        "points = [\n",
        "    PointStruct(\n",
        "        id=idx,\n",
        "        vector=embeddings[idx].tolist(),\n",
        "        payload={\n",
        "            \"text\": texts[idx],\n",
        "            \"metadata\": metadatas[idx]\n",
        "        }\n",
        "    )\n",
        "    for idx in range(len(texts))\n",
        "]\n",
        "\n",
        "client.upsert(\n",
        "    collection_name=\"quati_chunks\",\n",
        "    points=points\n",
        ")"
      ],
      "metadata": {
        "id": "xZ0Om_QOWX3I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Query check\n",
        "Abaixo, segue uma checagem rápida da busca vetorial através do Qdrant."
      ],
      "metadata": {
        "id": "-t1bzeaVW-Oc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a query\n",
        "query = clean_text(\"O que é o Imposto de Renda para Pessoa Física?\")\n",
        "query_emb = model.encode(query, normalize_embeddings=True)\n",
        "\n",
        "print(f\"Query: {query}\")\n",
        "print(f\"Query embedding: {query_emb}\")"
      ],
      "metadata": {
        "id": "ur6YrOeXXIzq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Search for chunks with similarity\n",
        "hits = client.search(\n",
        "    collection_name=\"quati_chunks\",\n",
        "    query_vector=query_emb.tolist(),\n",
        "    limit=k\n",
        ")\n",
        "\n",
        "for h in hits:\n",
        "    print(f\"Score: {h.score}\")\n",
        "    print(f\"Text: {h.payload['text']}\")\n",
        "    print(f\"Metadata: {h.payload['metadata']}\")\n",
        "    print(\"-\" * 100)"
      ],
      "metadata": {
        "id": "mEvuMqbKX8Pi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JtBM0myOY7ik"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}