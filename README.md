# **RAG-BR: Sistema de Recupera√ß√£o, Reranking e Resposta Baseada em Documentos em Portugu√™s com Modelo de Reranking Treinado**
## **Aplicando CRISP-DM para um problema de neg√≥cio**

- **Trabalho Final de P√≥s-Gradua√ß√£o**
- **Especializa√ß√£o em Data Science e Machine Learning**
- **Autor:** Alexandre Oliveira

---

## üéØ **Objetivo do Trabalho**

Este trabalho implementa um pipeline completo de **Recupera√ß√£o Aumentada por Gera√ß√£o (RAG)** para textos em portugu√™s, integrando **embeddings sem√¢nticos**, **indexa√ß√£o vetorial**, um **modelo de reranking treinado pelo autor** e um m√≥dulo de **resposta-resumo baseado em LLM**.

O sistema retorna documentos relevantes da base, apresenta o conjunto de evid√™ncias utilizado e gera uma resposta fundamentada, combinando t√©cnicas modernas de PLN, engenharia de modelos e princ√≠pios de MLOps. Todo o projeto segue rigorosamente a metodologia **CRISP-DM**, desde o entendimento do problema at√© o deploy final como uma API.

---

## üìö Documenta√ß√£o T√©cnica
A documenta√ß√£o detalhada do projeto est√° dispon√≠vel na pasta `docs/` (a revisar):

- [Relat√≥rios de Estudo](./docs/study_reports/)
- [Arquitetura do Sistema](./docs/refs/architecture.md)
- [Estrutura do Projeto](./docs/refs/project_structure.md)
- [Descri√ß√£o dos Datasets](./docs/refs/datasets_description.md)
- [Google Colab Notebooks](./docs/refs/colab_reference.md)
<!-- TODO: Mover documenta√ß√£o da metodologia CRISP-DM para docs/ -->
<!-- TODO: Mover descri√ß√£o do dataset para docs/ -->
<!-- TODO: Adicionar documenta√ß√£o sobre treinamento do Reranker -->
<!-- TODO: Adicionar documenta√ß√£o do pipeline RAG -->

Esses documentos servem como guia t√©cnico do projeto durante toda a implementa√ß√£o.

---

# üèóÔ∏è **Vis√£o Geral do Pipeline Proposto**

1. Usu√°rio envia **uma pergunta** ou **um documento**.  
2. Sistema gera um **embedding sem√¢ntico**.  
3. Busca inicial dos documentos mais similares via **FAISS** (top-k).  
4. Documentos s√£o reordenados pelo **modelo de reranking treinado** com pares do Quati.  
5. Os documentos reranqueados e reordenados s√£o passados para um **LLM** para gera√ß√£o de resposta.  
6. O sistema retorna:  
   - resposta fundamentada,  
   - lista dos documentos utilizados,  
   - scores de relev√¢ncia,  
   - ranking antes e depois do reranking.  
7. Deploy final via **FastAPI + Docker**.

---

# #Ô∏è‚É£ **CRISP-DM ‚Äî Estrutura Completa do Projeto**

---

# **1. Business Understanding**

### 1.1 Objetivo de Neg√≥cio  
Organiza√ß√µes, equipes de pesquisa e analistas lidam com grandes volumes de documentos. M√©todos tradicionais de busca por palavra-chave n√£o capturam significado ou contexto.

### 1.2 Problema de Neg√≥cio  
Como permitir que um usu√°rio recupere informa√ß√µes profundamente relevantes em uma grande base documental em portugu√™s e receba uma **resposta fundamentada**, sem depender de leitura manual exaustiva?

### 1.3 Objetivos de Minera√ß√£o de Dados  
- Construir um sistema de **recupera√ß√£o sem√¢ntica eficiente**.  
- Treinar um **modelo supervisionado de reranking**.  
- Integrar recupera√ß√£o + reranking + gera√ß√£o de resposta (RAG).  
- Expor o pipeline completo via **API**.  

### 1.4 Crit√©rios de Sucesso  
- Recall@K e NDCG significativamente melhores ap√≥s o reranking.  
- Respostas do LLM fundamentadas nos documentos recuperados.  
- API est√°vel e funcional para uso externo.  
- Pipeline reproduz√≠vel e bem documentado.

---

# **2. Data Understanding**

### 2.1 Coleta / Origem dos Dados  
Dataset Quati (HuggingFace):  
https://huggingface.co/datasets/unicamp-dl/quati

### 2.2 Limpeza Inicial dos Dados
- Remover textos com caracteres inv√°lidos.  
- Padroniza√ß√£o e normaliza√ß√£o b√°sica.  
- Remover blocos ruidosos (HTML, tags).

### 2.3 Descri√ß√£o dos Dados  
- Consultas escritas por falantes nativos.  
- Documentos de dom√≠nio variado (sites em portugu√™s).  
- Qrels que indicam quais documentos s√£o relevantes para cada consulta.  
- Conjunto adequado para avalia√ß√£o formal de pipelines de Information Retrieval (IR).

### 2.4 Explora√ß√£o Inicial  
- Distribui√ß√£o de tamanhos dos documentos.  
- Exemplos de consultas amb√≠guas vs diretas.  
- An√°lise do n√∫mero m√©dio de documentos relevantes por query.  
- Observa√ß√£o da diversidade de temas.  

### 2.5 Problemas Identificados
- Pouca quantidade de rela√ß√µes entre consultas e documentos.  
- Assimetrias entre positivas e negativas, sendo a maioria dos documentos irrelevantes.  
- Presen√ßa de ru√≠do em passagens; necessidade de limpeza cuidadosa.

---

# **3. Data Preparation**

### 3.1 Pr√©-processamento dos Textos  
- Remo√ß√£o de HTML e tags.  
- Normaliza√ß√£o Unicode.

### 3.2 Tokeniza√ß√£o e Chunking
Quebrar passagens muito longas em segmentos de 256‚Äì512 tokens.

### 3.3 Embeddings  
Modelos sugeridos:
- `sentence-transformers/paraphrase-multilingual-mpnet-base-v2`  
- `sentence-transformers/all-MiniLM-L6-v2`  
- `neuralmind/bert-base-portuguese-cased` (convertido para encoder)

### 3.4 Constru√ß√£o do √çndice Vetorial  
- FAISS (Flat, HNSW ou IVFFlat dependendo do experimento).
- Armazenar IDs + metadados em VectorDB ou similar.

### 3.5 Dataset para o Reranker
O reranker ser√° treinado com o dataset MS MARCO (em ingl√™s) por sua escala e qualidade de r√≥tulos, e aplicado em zero-shot ao Quati (em portugu√™s).

A utiliza√ß√£o de embeddings multil√≠ngues visa mitigar a barreira lingu√≠stica, al√©m da aplica√ß√£o de avalia√ß√µes qualitativas e m√©tricas de ranking necess√°rias para validar adaptabilidade cross-lingu√≠stica entre o MS MARCO e o Quati.

O dataset Quati ser√° utilizado para teste e avalia√ß√£o do reranker, atrav√©s das Qrels dispon√≠veis que possuem originalmente valores entre 0 e 3 para score de relev√¢ncia.

Outra considera√ß√£o importante √© que o modelo de reranking ser√° treinado como um modelo de **regress√£o**, prevendo scores cont√≠nuos de relev√¢ncia, sendo necess√°rio a normaliza√ß√£o dos labels originais para o intervalo [0, 1].

Dessa forma, o modelo aprende a gerar um score cont√≠nuo de relev√¢ncia, permitindo interpretabilidade mais fina e rankings mais expressivos.

A estrutura ideal para os datasets √© ent√£o: `(query, passage, label)`

---

# **4. Modelling**

### 4.1 Baseline ‚Äì Recupera√ß√£o por Embeddings  
Avalia√ß√£o inicial com FAISS puro:  
- Recall@K  
- NDCG  
- MRR  

### 4.2 Modelo Supervisionado de Reranking

O reranker ser√° um modelo **Cross-Encoder baseado em DistilBERT ou BERTimbau**, treinado como um modelo de regress√£o, produzindo um score cont√≠nuo de relev√¢ncia entre a consulta e a passagem.

Entrada: `[CLS] query [SEP] passage [SEP]`

Sa√≠da: `Score de relev√¢ncia`, sendo um valor escalar cont√≠nuo, entre 0 e 1.

Loss Functions recomendadas:
- Mean Squared Error (MSE) ‚Äî preferida pela simplicidade e estabilidade.
- Cosine Embedding Loss ‚Äî op√ß√£o alternativa quando queremos preservar rela√ß√µes sem√¢nticas.
- Pairwise Ranking Loss adaptada para regress√£o ‚Äî caso deseje priorizar ordena√ß√£o.

O uso de regress√£o permite capturar n√≠veis intermedi√°rios de relev√¢ncia e facilita a inspe√ß√£o manual do modelo, al√©m de alinhar melhor o uso do score no ranking final.

### 4.3 Pipeline RAG  
Fluxo final:
1. Embedding da query  
2. FAISS ‚Üí top-k  
3. Reranker ‚Üí reorder (documentos reordenados em ordem decrescente de relev√¢ncia)
4. LLM ‚Üí resposta consolidada  
5. Output estruturado

### 4.4 Modelos de Linguagem para Gera√ß√£o  
- GPT-4o-mini  
- Llama 3 8B Instruct  
- Phi-3-mini  

---

# **5. Evaluation**

### 5.1 Avalia√ß√£o da Recupera√ß√£o (pr√©-reranking)  
- Recall@K  
- Precision@K  
- NDCG@10  
- MRR  

### 5.2 Avalia√ß√£o do Reranking  
Comparar FAISS vs FAISS + Reranker:

| M√©trica | FAISS puro | FAISS + Reranker |
|--------|------------|------------------|
| Recall@5 | X | ‚Üë Y |
| MRR | X | ‚Üë Y |
| NDCG@10 | X | ‚Üë Y |

Como o reranker ser√° um modelo regressivo, que gera scores cont√≠nuos, a avalia√ß√£o do reranking utilizar√° tamb√©m m√©tricas de ranking baseadas nesses valores, como:
- Spearman Rank Correlation: correla√ß√£o entre ranking previsto e ranking ideal
- Kendall Tau: medida de concord√¢ncia entre rankings
- NDCG@K, agora utilizando diretamente os scores cont√≠nuos do modelo

### 5.3 Avalia√ß√£o do RAG  
- Verificar grounding das respostas.  
- Comparar qualidade com e sem reranking.  
- Avalia√ß√µes qualitativas e estudos de caso.

### 5.4 An√°lise de Erros  
- Consultas amb√≠guas.  
- Passagens muito curtas ou extensas.  
- Reranking invertendo documentos importantes.

---

# **6. Deployment**

### 6.1 API (FastAPI)  
Endpoints sugeridos:

- Para usu√°rio final:
```yaml
POST /query
  body: { "query": "...", "k": 5 }
  returns:
    - documentos recuperados (IDs, t√≠tulos, scores)
    - resposta s√≠ntese gerada pelo LLM
    - scores do reranker
```

- Para uso interno / testes:
```yaml
POST /embed
POST /rerank
POST /rag
```

### 6.2 Docker  
- Dockerfile (baseado em Python 3.10+)
- requirements.txt com depend√™ncias (a revisar):
    - fastapi
    - uvicorn
    - sentence-transformers
    - faiss
    - transformers
    - openai API ou huggingface
    - torch
- Uvicorn server  

### 6.3 Scripts Essenciais Execut√°veis
- `ingest.py` ‚Äì para ingest√£o e indexa√ß√£o; constr√≥i embeddings, chunks e √≠ndice FAISS  
- `train_reranker.py` ‚Äì treina o modelo supervisionado  
- `evaluate.py` ‚Äì executa todas as m√©tricas  
- `run_api.py` ‚Äì roda a API completa

### 6.4 Instru√ß√µes de Uso
- Como rodar a API
- Como treinar o reranker
- Como usar a aplica√ß√£o como usu√°rio final

<!-- ### 6.6 Interface b√°sica via Streamlit (opcional)
- Interface simples para testes manuais -->

<!-- ### 6.7 Monitoramento e Logs
- M√©tricas de lat√™ncia e throughput da API  
- Logs de requisi√ß√µes e erros via FastAPI middleware  
- Logs de erros e exce√ß√µes  
- Monitoramento b√°sico de performance (tempo de resposta, uso de mem√≥ria)
- Alertas para falhas cr√≠ticas -->

---

# **7. Conclus√µes**

### 7.1 S√≠ntese dos Resultados  
- Embeddings geram uma boa recupera√ß√£o inicial.  
- O reranker supervisionado melhora significativamente a qualidade final.  
- O pipeline RAG produz respostas fundamentadas e coerentes.  

### 7.2 Li√ß√µes Aprendidas Esperadas  
- Estrutura√ß√£o do trabalho via CRISP-DM.  
- Dados ruidosos exigem prepara√ß√£o cuidadosa.  
- Rerankers leves t√™m excelente custo-benef√≠cio.  

### 7.3 Trabalhos Futuros  
- Fine-tuning de embeddings customizados.  
- Amplia√ß√£o da base de documentos.  
- Avalia√ß√£o humana sistematizada.

---

# **8. Appendix**

- Exemplos de chamadas √† API  
- Amostras do dataset  
- Tabelas de m√©tricas adicionais  
- Links para notebooks de desenvolvimento