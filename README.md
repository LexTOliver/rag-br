# **RAG-BR: Sistema de Recupera√ß√£o, Reranking e Resposta Baseada em Documentos em Portugu√™s com Modelo de Reranking Treinado**
## **Aplicando CRISP-DM para um problema de neg√≥cio**

- **Trabalho Final de P√≥s-Gradua√ß√£o**
- **Autor:** Alexandre Oliveira
- **RA:** 52400856

---

## üéØ **Objetivo do Trabalho**

Este trabalho implementa um pipeline completo de **Recupera√ß√£o Aumentada por Gera√ß√£o (RAG)** para textos em portugu√™s, integrando **embeddings sem√¢nticos**, **indexa√ß√£o vetorial**, um **modelo de reranking treinado pelo autor** e um m√≥dulo de **resposta-resumo baseado em LLM**.

O sistema retorna documentos relevantes da base, apresenta o conjunto de evid√™ncias utilizado e gera uma resposta fundamentada, combinando t√©cnicas modernas de PLN, engenharia de modelos e princ√≠pios de MLOps. Todo o projeto segue rigorosamente a metodologia **CRISP-DM**, desde o entendimento do problema at√© o deploy final como uma API.

---

## üìö Documenta√ß√£o T√©cnica
A documenta√ß√£o detalhada do projeto est√° dispon√≠vel na pasta `docs/` (a revisar):

- [Relat√≥rios de Estudo](./docs/study_reports/)
- [Arquitetura do Sistema](./docs/refs/architecture.md)
- [Estrutura do Projeto](./docs/refs/project_structure.md)
<!-- TODO: Mover documenta√ß√£o da metodologia CRISP-DM para docs/ -->
<!-- TODO: Adicionar documento de Refer√™ncias dos Notebooks do Google Colab -->
<!-- TODO: Mover descri√ß√£o do dataset para docs/ -->
<!-- TODO: Adicionar documenta√ß√£o do pipeline RAG -->
<!-- TODO: Adicionar documenta√ß√£o sobre treinamento do Reranker -->

Esses documentos servem como guia t√©cnico durante toda a implementa√ß√£o.

---

# üß© **Descri√ß√£o Geral do Quati Dataset**

O [**Quati**](https://huggingface.co/datasets/unicamp-dl/quati) √© um dataset criado para tarefas de **Recupera√ß√£o de Informa√ß√£o (IR)** em l√≠ngua portuguesa, contendo consultas elaboradas por falantes nativos e passagens extra√≠das de sites brasileiros. Ele √© estruturado em tr√™s componentes principais:

1. **Passagens** (documentos)  
2. **Consultas** (queries)  
3. **Qrels** (rela√ß√£o consulta‚Äìpassagem com anota√ß√£o de relev√¢ncia)

O dataset est√° atualmente dispon√≠vel em duas vers√µes: uma com 1 milh√£o de passagens (`quati_1M_passages`) e outra maior, com 10 milh√µes de passagens (`quati_10M_passages`). At√© o momento, foram preparados apenas arquivos qrel de valida√ß√£o para ambas as vers√µes, anotando 50 t√≥picos com uma m√©dia de 97,78 passagens por consulta na vers√£o de 10 milh√µes de passagens e 38,66 passagens por consulta na vers√£o de 1 milh√£o de passagens.

Essa estrutura permite treinar e avaliar sistemas completos de IR, modelos supervisionados de reranking e pipelines RAG.

---

## üîé **Dicion√°rio de Dados**

### **1. Passagens** (`quati_1M_passages` / `quati_10M_passages`)
| Campo | Tipo | Descri√ß√£o |
|-------|------|-----------|
| `passage_id` | string | Identificador √∫nico da passagem/documento. |
| `passage` | string | Texto completo da passagem em portugu√™s. |

### **2. Topics / Consultas** (`quati_all_topics`, `quati_test_topics`, etc.)
| Campo | Tipo | Descri√ß√£o |
|-------|------|-----------|
| `query_id` | string/int | Identificador √∫nico da consulta. |
| `query` | string | Pergunta/consulta formulada por falante nativo. |

### **3. Qrels ‚Äî Relev√¢ncia** (`quati_1M_qrels` / `quati_10M_qrels`)
| Campo | Tipo | Descri√ß√£o |
|-------|------|-----------|
| `query_id` | string/int | ID da consulta associada. |
| `passage_id` | string | ID da passagem correspondente. |
| `score` | int | Grau de relev√¢ncia do documento para a consulta (0 ou 1 no dataset). |

---

# üèóÔ∏è **Vis√£o Geral do Pipeline Proposto**

1. Usu√°rio envia **uma pergunta** ou **um documento**.  
2. Sistema gera um **embedding sem√¢ntico**.  
3. Busca inicial dos documentos mais similares via **FAISS** (top-k).  
4. Documentos s√£o reordenados pelo **modelo de reranking treinado** com pares do Quati.  
5. Os documentos reranqueados e reordenados s√£o passados para um **LLM** para gera√ß√£o de resposta.  
6. O sistema retorna:  
   - resposta fundamentada,  
   - lista dos documentos utilizados,  
   - scores de relev√¢ncia,  
   - ranking antes e depois do reranking.  
7. Deploy final via **FastAPI + Docker**.

---

# #Ô∏è‚É£ **CRISP-DM ‚Äî Estrutura Completa do Projeto**

---

# **1. Business Understanding**

### 1.1 Objetivo de Neg√≥cio  
Organiza√ß√µes, equipes de pesquisa e analistas lidam com grandes volumes de documentos. M√©todos tradicionais de busca por palavra-chave n√£o capturam significado ou contexto.

### 1.2 Problema de Neg√≥cio  
Como permitir que um usu√°rio recupere informa√ß√µes profundamente relevantes em uma grande base documental em portugu√™s e receba uma **resposta fundamentada**, sem depender de leitura manual exaustiva?

### 1.3 Objetivos de Minera√ß√£o de Dados  
- Construir um sistema de **recupera√ß√£o sem√¢ntica eficiente**.  
- Treinar um **modelo supervisionado de reranking** usando o Quati.  
- Integrar recupera√ß√£o + reranking + gera√ß√£o de resposta (RAG).  
- Expor o pipeline completo via **API**.  

### 1.4 Crit√©rios de Sucesso  
- Recall@K e NDCG significativamente melhores ap√≥s o reranking.  
- Respostas do LLM fundamentadas nos documentos recuperados.  
- API est√°vel e funcional para uso externo.  
- Pipeline reproduz√≠vel e bem documentado.

---

# **2. Data Understanding**

### 2.1 Coleta / Origem dos Dados  
Dataset Quati (HuggingFace):  
https://huggingface.co/datasets/unicamp-dl/quati

### 2.2 Descri√ß√£o dos Dados  
- Consultas escritas por falantes nativos.  
- Passagens de dom√≠nio variado (sites em portugu√™s).  
- Qrels que indicam quais passagens s√£o relevantes para cada consulta.  
- Conjunto adequado para avalia√ß√£o formal de pipelines de Information Retrieval (IR).

### 2.3 Explora√ß√£o Inicial (esperada no notebook)  
- Distribui√ß√£o de tamanhos das passagens.  
- Exemplos de consultas amb√≠guas vs diretas.  
- An√°lise do n√∫mero m√©dio de documentos relevantes por query.  
- Observa√ß√£o da diversidade de temas.  

### 2.4 Problemas Poss√≠veis  
- Documentos extensos precisam de **chunking**.  
- Algumas consultas s√£o curtas demais.  
- Assimetrias entre positivas e negativas.  
- Varia√ß√£o grande de estilo lingu√≠stico.

---

# **3. Data Preparation**

### 3.1 Limpeza
- Remover textos com caracteres inv√°lidos.  
- Padroniza√ß√£o e normaliza√ß√£o b√°sica.  
- Remover blocos ruidosos (HTML, tags).

### 3.2 Tokeniza√ß√£o / Embeddings  
Modelos sugeridos:
- `sentence-transformers/paraphrase-multilingual-mpnet-base-v2`  
- `sentence-transformers/all-MiniLM-L6-v2`  
- `neuralmind/bert-base-portuguese-cased` (convertido para encoder)

### 3.3 Chunking  
Quebrar passagens muito longas em segmentos de 256‚Äì512 tokens.

### 3.4 Constru√ß√£o do √çndice Vetorial  
- FAISS (Flat, HNSW ou IVFFlat dependendo do experimento).
- Armazenar IDs + metadados.

### 3.5 Dataset para o Reranker  

O dataset de reranking ser√° preparado utilizando os Qrels, onde score √© originalmente bin√°rio (0 ou 1), mas ser√° tratado como um alvo cont√≠nuo em uma tarefa de regress√£o.

Dessa forma, o modelo aprende a gerar um score cont√≠nuo de relev√¢ncia, permitindo interpretabilidade mais fina e rankings mais expressivos.

Montado a partir dos Qrels: `(query, passage, label)`

>Obs.:
  label = 1 se score=1 em `qrels`;
  label = 0 se score=0

---

# **4. Modeling**

### 4.1 Baseline ‚Äì Recupera√ß√£o por Embeddings  
Avalia√ß√£o inicial com FAISS puro:  
- Recall@K  
- NDCG  
- MRR  

### 4.2 Modelo Supervisionado de Reranking

O reranker ser√° um modelo **Cross-Encoder baseado em DistilBERT ou BERTimbau**, treinado como um modelo de regress√£o, produzindo um score cont√≠nuo de relev√¢ncia entre a consulta e a passagem.

Entrada: `[CLS] query [SEP] passage [SEP]`

Sa√≠da: `Score de relev√¢ncia`, sendo um valor escalar cont√≠nuo, entre 0 e 1.

Loss Functions recomendadas:
- Mean Squared Error (MSE) ‚Äî preferida pela simplicidade e estabilidade.
- Cosine Embedding Loss ‚Äî op√ß√£o alternativa quando queremos preservar rela√ß√µes sem√¢nticas.
- Pairwise Ranking Loss adaptada para regress√£o ‚Äî caso deseje priorizar ordena√ß√£o.

O uso de regress√£o permite capturar n√≠veis intermedi√°rios de relev√¢ncia e facilita a inspe√ß√£o manual do modelo, al√©m de alinhar melhor o uso do score no ranking final.

### 4.3 Pipeline RAG  
Fluxo final:
1. Embedding da query  
2. FAISS ‚Üí top-k  
3. Reranker ‚Üí reorder (documentos reordenados em ordem decrescente de relev√¢ncia)
4. LLM ‚Üí resposta consolidada  
5. Output estruturado

### 4.4 Modelos de Linguagem para Gera√ß√£o  
- GPT-4o-mini  
- Llama 3 8B Instruct  
- Phi-3-mini  

---

# **5. Evaluation**

### 5.1 Avalia√ß√£o da Recupera√ß√£o (pr√©-reranking)  
- Recall@K  
- Precision@K  
- NDCG@10  
- MRR  

### 5.2 Avalia√ß√£o do Reranking  
Comparar FAISS vs FAISS + Reranker:

| M√©trica | FAISS puro | FAISS + Reranker |
|--------|------------|------------------|
| Recall@5 | X | ‚Üë Y |
| MRR | X | ‚Üë Y |
| NDCG@10 | X | ‚Üë Y |

Como o reranker ser√° um modelo regressivo, que gera scores cont√≠nuos, a avalia√ß√£o do reranking utilizar√° tamb√©m m√©tricas de ranking baseadas nesses valores, como:
- Spearman Rank Correlation: correla√ß√£o entre ranking previsto e ranking ideal
- Kendall Tau: medida de concord√¢ncia entre rankings
- NDCG@K, agora utilizando diretamente os scores cont√≠nuos do modelo

### 5.3 Avalia√ß√£o do RAG  
- Verificar grounding das respostas.  
- Comparar qualidade com e sem reranking.  
- Avalia√ß√µes qualitativas e estudos de caso.

### 5.4 An√°lise de Erros  
- Consultas amb√≠guas.  
- Passagens muito curtas ou extensas.  
- Reranking invertendo documentos importantes.

---

# **6. Deployment**

### 6.1 API (FastAPI)  
Endpoints sugeridos:

- Para usu√°rio final:
```yaml
POST /query
  body: { "query": "...", "k": 5 }
  returns:
    - documentos recuperados (IDs, t√≠tulos, scores)
    - resposta s√≠ntese gerada pelo LLM
    - scores do reranker
```

- Para uso interno / testes:
```yaml
POST /embed
POST /rerank
POST /rag
```

### 6.2 Docker  
- Dockerfile (baseado em Python 3.10+)
- requirements.txt com depend√™ncias (a revisar):
    - fastapi
    - uvicorn
    - sentence-transformers
    - faiss
    - transformers
    - openai API ou huggingface
    - torch
- Uvicorn server  

### 6.3 Scripts Essenciais Execut√°veis
- `ingest.py` ‚Äì para ingest√£o e indexa√ß√£o; constr√≥i embeddings, chunks e √≠ndice FAISS  
- `train_reranker.py` ‚Äì treina o modelo supervisionado  
- `evaluate.py` ‚Äì executa todas as m√©tricas  
- `run_api.py` ‚Äì roda a API completa

### 6.4 Instru√ß√µes de Uso
- Como rodar a API
- Como treinar o reranker
- Como usar a aplica√ß√£o como usu√°rio final

<!-- ### 6.6 Interface b√°sica via Streamlit (opcional)
- Interface simples para testes manuais -->

<!-- ### 6.7 Monitoramento e Logs
- M√©tricas de lat√™ncia e throughput da API  
- Logs de requisi√ß√µes e erros via FastAPI middleware  
- Logs de erros e exce√ß√µes  
- Monitoramento b√°sico de performance (tempo de resposta, uso de mem√≥ria)
- Alertas para falhas cr√≠ticas -->

---

# **7. Conclus√µes**

### 7.1 S√≠ntese dos Resultados  
- Embeddings geram uma boa recupera√ß√£o inicial.  
- O reranker supervisionado melhora significativamente a qualidade final.  
- O pipeline RAG produz respostas fundamentadas e coerentes.  

### 7.2 Li√ß√µes Aprendidas Esperadas  
- Estrutura√ß√£o do trabalho via CRISP-DM.  
- Dados ruidosos exigem prepara√ß√£o cuidadosa.  
- Rerankers leves t√™m excelente custo-benef√≠cio.  

### 7.3 Trabalhos Futuros  
- Fine-tuning de embeddings customizados.  
- Amplia√ß√£o da base de documentos.  
- Avalia√ß√£o humana sistematizada.

---

# **8. Appendix**

- Exemplos de chamadas √† API  
- Amostras do dataset  
- Tabelas de m√©tricas adicionais  
- Links para notebooks de desenvolvimento